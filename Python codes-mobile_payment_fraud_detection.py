# -*- coding: utf-8 -*-
"""Mobile payment fraud detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17Ots-b_QHPaz4Gv3rEGjdIDU_05tFdH7
"""

from google.colab import auth
auth.authenticate_user()
from googleapiclient.discovery import build
drive_service = build('drive', 'v3')
from google.colab import drive
drive.mount('/content/drive',force_remount=True)

import numpy as np 
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV,train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as pl2
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score,classification_report,roc_auc_score,precision_score,recall_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense,Input,BatchNormalization
from keras.utils import to_categorical
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam
from keras.wrappers.scikit_learn import KerasClassifier

df = pd.read_csv("/content/drive/My Drive/DM/Mobile payment fraud/PS_20174392719_1491204439457_log.csv")
df.head()

df.shape

df.isnull().sum()

#Transaction hour-Extracting the hour information
df['transactionHour'] = df['step'] % 24
# converting into object type
df['transactionHour'] = df['transactionHour'].astype('object')

#Making the transaction amount units to thousands
df['th_amount'] = df['amount'] / 1000

#Deriving a label to denote whether the transfer happened from Customer to Merchant or from Customer to Customer
df['transactionBetween'] = df['nameDest'].apply(lambda x: 'Customer2Customer' if x[0] == "C" else 'Customer2Merchant')

#Categorizing the hour value into peak hour, mid hour, and least hour based on the proportion of fraud happening
df['transactionPeriod'] = df['transactionHour'].apply(lambda x: 'Peak' if x in [2,3,4,5,6] else
                                                                ('Mid' if x in [22,23,0,1,7,8] else 'Safe'))

#Finding the Error in origin account balance amount
#Error = (New Balance + Transaction Amount) - Old Balance
df['errorBalanceOrig'] = df['newbalanceOrig'] + df['amount'] - df['oldbalanceOrg']

#Finding the Error in destination account balance amount
#Error = (Old Balance + Transaction Amount) - New Balance
df['errorBalanceDest'] = df['oldbalanceDest'] + df['amount'] - df['newbalanceDest']

#Flag to indicate zero origin account balance
df['zeroBalanceOrig'] = df['oldbalanceOrg'] + df['newbalanceOrig']
df['zeroBalanceOrig'] = df['zeroBalanceOrig'].apply(lambda x: 1 if x == 0 else 0)

#Flag to indicate zero destination account balance
df['zeroBalanceDest'] = df['oldbalanceDest'] + df['newbalanceDest']
df['zeroBalanceDest'] = df['zeroBalanceDest'].apply(lambda x: 1 if x == 0 else 0)

df.shape

df.head()

"""Exploratory data analysis"""

# fraudulent transactions
# countplot to visualize the no. of observations under each class
ax = df['isFraud'].value_counts().plot(kind='bar',color='orange')
plt.xlabel('Transaction Type', fontsize=15, fontweight='bold')
plt.xticks(ticks=[0,1], labels=['Non-Fraud','Fraud'], rotation=0, fontsize=12, fontweight='bold')
plt.ylabel('No. of observations (Millions)', fontsize=15, fontweight='bold')
plt.yticks(fontsize=12, fontweight='bold')
plt.title('No. of obervations in each class', fontsize=18, fontweight='bold')
for i in ax.patches:
    # get_x pulls left or right; get_height pushes up or down
    ax.text(i.get_x()+0.1, i.get_height()+3, str(round(i.get_height(), 2)), fontsize=15, color='black')

fig,axs = plt.subplots(2,3,figsize=(12,6))
axs[0][0].title.set_text('Histogram of transaction amount')
axs[0][0].hist(df["amount"])
axs[0][1].title.set_text("Histogram of opening customer balance")
axs[0][1].hist(df["oldbalanceOrg"])
axs[1][0].title.set_text("Histogram of closing customer balance")
axs[1][0].hist(df["newbalanceOrig"])
axs[1][1].title.set_text("Histogram of clsoing recipient balance")
axs[1][1].hist(df["newbalanceDest"])
axs[0][2].hist(df["errorBalanceDest"])
axs[1][2].hist(df["errorBalanceOrig"])
plt.show()

df[['oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']].hist(bins=30,color='orange');

#Skewness in variable
def skewness(var):
  print("Summary statistics:\n", df[var].describe().round(2))
  print("-"*100)

df["errorBalanceDest"]=df["errorBalanceDest"].apply(lambda x: 0 if x< 0 else x)
df["errorBalanceOrig"]=df["errorBalanceOrig"].apply(lambda x: 0 if x< 0 else x)

#log transforming all variables-
df["logamount"] = np.log1p(df["th_amount"])
df["logoldbalanceOrg"] = np.log1p(df["oldbalanceOrg"])
df["lognewbalanceOrig"] = np.log1p(df["newbalanceOrig"])
df["logoldbalanceDest"] = np.log1p(df["oldbalanceDest"])
df["lognewbalanceDest"] = np.log1p(df["newbalanceDest"])
df["logerrorBalanceDest"] = np.log1p(df["errorBalanceDest"])
df["logerrorBalanceOrig"] = np.log1p(df["errorBalanceOrig"])

df[['logoldbalanceOrg','lognewbalanceOrig','logoldbalanceDest','lognewbalanceDest']].hist(bins=30,color='orange');

#log transform of all features

fig,axs = plt.subplots(2,3,figsize=(12,6))
axs[0][0].title.set_text('Histogram of transaction amount')
axs[0][0].hist(df["logamount"])
axs[0][1].title.set_text("Histogram of opening customer balance")
axs[0][1].hist(df["logoldbalanceOrg"])
axs[1][0].title.set_text("Histogram of closing customer balance")
axs[1][0].hist(df["lognewbalanceOrig"])
axs[1][1].title.set_text("Histogram of clsoing recipient balance")
axs[1][1].hist(df["lognewbalanceDest"])
axs[0][2].hist(df["logerrorBalanceDest"])
axs[1][2].hist(df["logerrorBalanceOrig"])
plt.show()

# Preparing new data with relevant coloums
df_new=df[['type','transactionPeriod','transactionBetween','logamount','logerrorBalanceDest','logerrorBalanceOrig','zeroBalanceOrig','zeroBalanceDest','isFraud']]

#Creating dummies
df_new = pd.get_dummies(df_new,columns=['type','transactionPeriod','transactionBetween'])

#applying standard scaling
df_prep=df_new.copy()
col_names = ['logamount', 'logerrorBalanceDest', 'logerrorBalanceOrig']
features = df_prep[col_names]
scaler = StandardScaler().fit(features.values)
features = scaler.transform(features.values)
df_prep[col_names]=features
df_prep.head()

#Train-test spilt (using startify option to ensure equal distribution of both fraud and non-fraud cases)
X_train,X_test,y_train,y_test=train_test_split(df_prep.drop("isFraud",axis=1),df_new["isFraud"],test_size=0.1,random_state=1234,stratify = df_prep["isFraud"])

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

print(y_test.value_counts())
print(y_train.value_counts())

"""Imbalanced datasets-downsampling majority class,upsampling minority class"""

#creating the train & test dataframes for further processing
df_train=X_train
df_train['isFraud']=y_train
#Down sampling majority class
df_train_downsampled = df_train[df_train['isFraud'] == 0].sample(250000, random_state=1)
#Up sampling minority class - Simple bootstrapping
df_train2 = pd.concat([df_train_downsampled, df_train[df_train['isFraud'] == 1].sample(250000, replace=True, random_state=1)],
                                           axis=0)
df_train2.shape

df_train2.isFraud.value_counts()

#getting the final train and test spilt
X_train=df_train2.drop(['isFraud'], axis=1)
y_train=df_train2.pop('isFraud')
print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

#from imblearn.over_sampling import SMOTE
#smote = SMOTE(random_state=33)
#X_train_s, y_train_s = smote.fit_sample(X_train, y_train)

#decision tree
from sklearn.tree import DecisionTreeClassifier,plot_tree
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as pl2
from sklearn.model_selection import cross_val_score,cross_val_predict

dt = DecisionTreeClassifier(random_state=1)
m1_dt=dt.fit(X_train,y_train)

y_pred_dt=dt.predict(X_test)

from sklearn.metrics import roc_curve
from sklearn.metrics import auc

# Compute fpr, tpr, thresholds and roc auc
fpr, tpr, thresholds = roc_curve(y_test, y_pred_dt)
#roc_auc = auc(y_train, dt_score[:,1])

# Plot ROC curve
plt.plot(fpr, tpr, label='ROC curve',color='orange')
plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate or (1 - Specifity)')
plt.ylabel('True Positive Rate or (Sensitivity)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

from sklearn import metrics 
print(metrics.classification_report(y_test,y_pred_dt,target_names=["Not Fraud", "Fraud"]))

from sklearn.ensemble import RandomForestClassifier
rfc=RandomForestClassifier(random_state=100)

m2_rfc=rfc.fit(X_train,y_train)

y_pred_rfc=rfc.predict(X_test)

print(metrics.classification_report(y_test, y_pred_rfc,target_names=["Not Fraud", "Fraud"]))

# Compute fpr, tpr, thresholds and roc auc
fpr_f, tpr_f, thresholds_f = roc_curve(y_test, y_pred_rfc)
#roc_auc = auc(y_train, dt_score[:,1])

# Plot ROC curve
plt.plot(fpr, tpr, label='DT',color='orange')
plt.plot(fpr_f, tpr_f, label='RFC',color='green')
plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate or (1 - Specifity)')
plt.ylabel('True Positive Rate or (Sensitivity)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

#plt.subplots(figsize=(18,10))
#plot_tree(dt_clf,feature_names = list(X_train_final.columns),filled=True, fontsize=12)

"""Neural Networks"""

# creating dummies for target variable
y_train_binary = pd.get_dummies(y_train)
y_test_n=pd.get_dummies(y_test)

from tensorflow import keras

# below are hyperparameters used for the experiments
batch_size=40
num_epochs=10
validate_pct=0.1
learning_rate = 1e-3
loss_function='binary_crossentropy'
optimization_function='rmsprop'
metric=[keras.metrics.BinaryAccuracy()]

InputLayer=Input(shape=(X_train.shape[1:]))

# simple feed forward NN
model_ann = Sequential()
model_ann.add(InputLayer)
model_ann.add(Dense(32, activation='relu'))
#model_ann.add(Dropout(0.3))
model_ann.add(Dense(64, activation='relu'))
#model_ann.add(Dropout(0.3))
model_ann.add(Dense(8, activation='relu'))
# model_ann.add(Dropout(0.3))
model_ann.add(Dense(2, activation='softmax'))

# model framework
model_ann.summary()

# training ANN
model_ann.compile(loss=loss_function, optimizer=optimization_function, metrics=metric)
model_history = model_ann.fit(X_train, y_train_binary,
                              batch_size=batch_size,
                              epochs=num_epochs,
                              validation_split=validate_pct,
                              shuffle=True,
                              verbose=True)

results=model_ann.evaluate(X_test, y_test_n,verbose=0)
print('test_acc:',results[1])

y_pred_nn=model_ann.predict([X_test])
#y_pred=y_pred['y_pred'].apply(lambda x: 1 if x > 0.5 else 0)
y_pred_N=(y_pred_nn >= 0.5).astype(np.int)
y_true=np.array(y_test)

y_pred_n = pd.DataFrame(model_ann.predict(X_test))[1].apply(lambda x: 1 if x > 0.5 else 0)

print(y_train.shape,y_pred.shape)



#cm = confusion_matrix(y_true, y_pred)
print(classification_report(y_test, y_pred_n, target_names=["Not Fraud", "Fraud"]))

fpr_N, tpr_N, thresholds_N = roc_curve(y_test, y_pred_n)
#roc_auc = auc(y_train, dt_score[:,1])

# Plot ROC curve
plt.plot(fpr, tpr, label='DT',color='green')
plt.plot(fpr_f, tpr_f, label='RFC',color='orange')
plt.plot(fpr_N, tpr_N, label='NN',color='blue')
plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate or (1 - Specifity)')
plt.ylabel('True Positive Rate or (Sensitivity)')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")